{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install lightgbm -i https://pypi.tuna.tsinghua.edu.cn/simple \n",
    "#下载需要的库与包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dataFile = ''\n",
    "data = pd.read_csv(dataFile)\n",
    "x=data.iloc[:,1:]\n",
    "y=data.iloc[:,0]\n",
    "x_std=MinMaxScaler().fit_transform(x)\n",
    "data_std=pd.concat([y,x_std],axis=1)\n",
    "data_std.to_csv('', header=True, index=False)\n",
    "data_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, levene\n",
    "from scipy.stats import mannwhitneyu\n",
    "dataFile = ''\n",
    "data = pd.read_csv(dataFile)\n",
    "data_a = data[data['label'] = 0]\n",
    "data_b = data[data['label'] = 1]\n",
    "X_a = data_a.iloc[:, 1:]\n",
    "y_a = data_a['label']\n",
    "X_b = data_b.iloc[:, 1:]\n",
    "y_b = data_b['label']\n",
    "print(X_a.shape, X_b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNamesSel_mwU = []\n",
    "for colName in X_a.columns[:]:\n",
    "    if mannwhitneyu(X_a[colName], X_b[colName])[1] < 0.05:\n",
    "print(len(colNamesSel_mwU))\n",
    "print(colNamesSel_mwU)\n",
    "xs=pd.DataFrame(data, columns=colNamesSel_mwU)\n",
    "xs\n",
    "Xs = pd.concat([y,xs],axis=1)\n",
    "Xs.to_csv('', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df=pd.read_csv('')\n",
    "y=df.iloc[:,0]\n",
    "x=df.iloc[:,1:]\n",
    "print(x.shape)\n",
    "\n",
    "x=x.T.drop_duplicates().T\n",
    "corr_matrix = x.corr(method='spearman')\n",
    "print(corr_matrix)\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > :  。\n",
    "            colname = corr_matrix.columns[i]\n",
    "            to_drop.append(colname)\n",
    "\n",
    "#删除相关系数大于0.8的特征\n",
    "data = x.drop(to_drop, axis=1)\n",
    "print(data.shape)\n",
    "data=pd.concat([y,data],axis=1)\n",
    "data.to_csv('',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages()\n",
    "library(glmnet)\n",
    "bc<-read.csv(\"相关系数.csv\",sep=',',header=TRUE)#读取我们的文件\n",
    "x <- as.matrix(bc[,2:195])#要多少列数据作为你的变量\n",
    "y <- bc[,1]#要那列数据作为你的结局\n",
    "fit <- glmnet(x,y,alpha=1,family=\"binomial\")\n",
    "plot(fit,xvar=\"lambda\",label=F,lwd=2)\n",
    "cvfit <- cv.glmnet(x,y,type.measure = \"auc\",alpha=1,family=\"binomial\")#type.measure 可以是“mse”，就是最常见的lasso，”\n",
    "plot(cvfit,xlab=\"Log lambda\",lwd=3,sign.lambda=1)\n",
    "print(cvfit)\n",
    "bc=coef(cvfit,s=cvfit$lambda.min)#min第一根线，最小值 1se第二根线\n",
    "bc\n",
    "\n",
    "coef = coef(fit, s = cvfit$lambda.min) \n",
    "index = which(coef != 0) \n",
    "actCoef = coef[index] \n",
    "actCoef\n",
    "lassoGene = row.names(coef)[index] \n",
    "lassoGene\n",
    "lassoGene = row.names(coef)[index]\n",
    "bc<-read.csv(\"相关系数.csv\",sep=',',header=TRUE)#读取我们的文件\n",
    "newdf<- bc[ ,colnames(bc) %in% lassoGene]\n",
    "View(newdf)\n",
    "write.csv(newdf,file = \"LASSO.csv \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV\n",
    "df=pd.read_csv('./feature/相关系数.csv')\n",
    "x=df.iloc[:,1:]\n",
    "y = df['label']\n",
    "columnNames=x.columns\n",
    "x = x.astype(np.float32)\n",
    "#x = StandardScaler().fit_transform(x)\n",
    "x = pd.DataFrame(x,columns=columnNames)\n",
    "lassoCV_model = LassoCV(alphas=alphas,cv=10,max_iter=10000)\n",
    "lassoCV_model.fit(x,y)\n",
    "\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lassoCV_model.alpha_)\n",
    "print(lassoCV_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.columns[lassoCV_model.coef_!=0])\n",
    "print(lassoCV_model.coef_!=0)\n",
    "print(len(x.columns[lassoCV_model.coef_!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lc=df[x.columns[lassoCV_model.coef_!=0]]\n",
    "data_lc=pd.concat([y,data_lc],axis=1)\n",
    "data_lc.to_csv('./feature/LASSO.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=lassoCV_model.path(x,y,alphas=alphas,max_iter=1000)[1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.semilogx(lassoCV_model.alphas_,coefs,'-')\n",
    "plt.axvline(lassoCV_model.alpha_,color='black',ls='--')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.savefig('LASSO1.svg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_mean=lassoCV_model.mse_path_.mean(axis=1)\n",
    "mse_std=lassoCV_model.mse_path_.std(axis=1)\n",
    "\n",
    "alpha_index=np.where(lassoCV_model.alphas_==lassoCV_model.alpha_)\n",
    "print('最佳mse的lambda位置',alpha_index)\n",
    "mses_mean_Se=mses_mean[alpha_index]+mse_std[alpha_index]\n",
    "print('最小mse一倍标准误差处',mses_mean_Se)\n",
    "alpha_index_Se=np.min(np.where(mses_mean<=mses_mean_Se))\n",
    "print('最小mse一倍标准误差处的lambda位置',alpha_index_Se)\n",
    "alpha_se=lassoCV_model.alphas_[alpha_index_Se]\n",
    "print('最近lambda的值',alpha_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.errorbar(lassoCV_model.alphas_,mses_mean\n",
    "             ,yerr=mse_std\n",
    "             ,fmt='o'\n",
    "             ,ms=2\n",
    "             ,mfc='r'\n",
    "             ,mec='r'\n",
    "             ,ecolor='lightgray'\n",
    "             ,elinewidth=2\n",
    "             ,capsize=2\n",
    "             ,capthick=1)\n",
    "plt.semilogx()\n",
    "plt.axvline(lassoCV_model.alpha_,color='black',ls='--')\n",
    "plt.axvline(alpha_se,color='black',ls='--')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Mse')\n",
    "plt.savefig('LASSO2.svg', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 建立模型\n",
    "def create_clf_model(model_names):\n",
    "    models = {}\n",
    "    # 判断是纯字符串，使用默认参数进行配置\n",
    "    if isinstance(model_names, (list, tuple)):\n",
    "        # SVM\n",
    "        if 'svm' in model_names or 'SVM' in model_names:\n",
    "            models['SVM'] = SVC(probability=True, random_state=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['SVM',]\n",
    "models = create_clf_model(model_names)\n",
    "model_names = list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('')\n",
    "labels = ['label']\n",
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(\n",
    "    data.iloc[:, 1:], data.iloc[:, 0], test_size=0.3,random_state=1)\n",
    "y_test_sel = pd.DataFrame(y_test_sel, columns=['label'])\n",
    "y_train_sel = pd.DataFrame(y_train_sel, columns=['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def compute_midrank(x):\n",
    "    \"\"\"Computes midranks.\n",
    "    Args:\n",
    "       x - a 1D numpy array\n",
    "    Returns:\n",
    "       array of midranks\n",
    "    \"\"\"\n",
    "    J = np.argsort(x)\n",
    "    Z = x[J]\n",
    "    N = len(x)\n",
    "    T = np.zeros(N, dtype=np.float64)\n",
    "    i = 0\n",
    "    while i < N:\n",
    "        j = i\n",
    "        while j < N and Z[j] == Z[i]:\n",
    "            j += 1\n",
    "        T[i:j] = 0.5 * (i + j - 1)\n",
    "        i = j\n",
    "    T2 = np.empty(N, dtype=np.float64)\n",
    "    # Note(kazeevn) +1 is due to Python using 0-based indexing\n",
    "    # instead of 1-based in the AUC formula in the paper\n",
    "    T2[J] = T + 1\n",
    "    return T2\n",
    "\n",
    "\n",
    "def fastDeLong(predictions_sorted_transposed, label_1_count):\n",
    "    \"\"\"\n",
    "    The fast version of DeLong's method for computing the covariance of\n",
    "    unadjusted AUC.\n",
    "    Args:\n",
    "       predictions_sorted_transposed: a 2D numpy.array[n_classifiers, n_examples]\n",
    "          sorted such as the examples with label \"1\" are first\n",
    "    Returns:\n",
    "       (AUC value, DeLong covariance)\n",
    "    Reference:\n",
    "     @article{sun2014fast,\n",
    "       title={Fast Implementation of DeLong's Algorithm for\n",
    "              Comparing the Areas Under Correlated Receiver Operating Characteristic Curves},\n",
    "       author={Xu Sun and Weichao Xu},\n",
    "       journal={IEEE Signal Processing Letters},\n",
    "       volume={21},\n",
    "       number={11},\n",
    "       pages={1389--1393},\n",
    "       year={2014},\n",
    "       publisher={IEEE}\n",
    "     }\n",
    "    \"\"\"\n",
    "    # Short variables are named as they are in the paper\n",
    "    m = label_1_count\n",
    "    n = predictions_sorted_transposed.shape[1] - m\n",
    "    positive_examples = predictions_sorted_transposed[:, :m]\n",
    "    negative_examples = predictions_sorted_transposed[:, m:]\n",
    "    k = predictions_sorted_transposed.shape[0]\n",
    "\n",
    "    tx = np.empty([k, m], dtype=np.float64)\n",
    "    ty = np.empty([k, n], dtype=np.float64)\n",
    "    tz = np.empty([k, m + n], dtype=np.float64)\n",
    "    for r in range(k):\n",
    "        tx[r, :] = compute_midrank(positive_examples[r, :])\n",
    "        ty[r, :] = compute_midrank(negative_examples[r, :])\n",
    "        tz[r, :] = compute_midrank(predictions_sorted_transposed[r, :])\n",
    "    aucs = tz[:, :m].sum(axis=1) / m / n - float(m + 1.0) / 2.0 / n\n",
    "    v01 = (tz[:, :m] - tx[:, :]) / n\n",
    "    v10 = 1.0 - (tz[:, m:] - ty[:, :]) / m\n",
    "    sx = np.cov(v01)\n",
    "    sy = np.cov(v10)\n",
    "    delongcov = sx / m + sy / n\n",
    "    return aucs, delongcov\n",
    "\n",
    "\n",
    "def calc_pvalue(aucs, sigma, logv=10):\n",
    "    \"\"\"Computes log(10) of p-values.\n",
    "    Args:\n",
    "       aucs: 1D array of AUCs\n",
    "       sigma: AUC DeLong covariances\n",
    "       logv:\n",
    "    Returns:\n",
    "       log10(pvalue)\n",
    "    \"\"\"\n",
    "    l = np.array([[1, -1]])\n",
    "    z = np.abs(np.diff(aucs)) / np.sqrt(np.dot(np.dot(l, sigma), l.T))\n",
    "    # print(np.sqrt(np.dot(np.dot(l, sigma), l.T)))\n",
    "    return 10 ** (np.log10(2) + scipy.stats.norm.logsf(z, loc=0, scale=1) / np.log(logv))\n",
    "\n",
    "\n",
    "def compute_ground_truth_statistics(ground_truth):\n",
    "    assert np.array_equal(np.unique(ground_truth), [0, 1])\n",
    "    order = (-ground_truth).argsort()\n",
    "    label_1_count = int(ground_truth.sum())\n",
    "    return order, label_1_count\n",
    "\n",
    "\n",
    "def delong_roc_variance(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC variance for a single set of predictions\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions: np.array of floats of the probability of being class 1\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = predictions[np.newaxis, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    assert len(\n",
    "        aucs) == 1, \"There is a bug in the code, please forward this to the developers\"\n",
    "    return aucs[0], delongcov\n",
    "\n",
    "\n",
    "def delong_roc_test(ground_truth, predictions_one, predictions_two, logv=10):\n",
    "    \"\"\"\n",
    "    Computes log(p-value) for hypothesis that two ROC AUCs are different\n",
    "    Args:\n",
    "       ground_truth: np.array of 0 and 1\n",
    "       predictions_one: predictions of the first model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       predictions_two: predictions of the second model,\n",
    "          np.array of floats of the probability of being class 1\n",
    "       logv:\n",
    "    \"\"\"\n",
    "    order, label_1_count = compute_ground_truth_statistics(ground_truth)\n",
    "    predictions_sorted_transposed = np.vstack(\n",
    "        (predictions_one, predictions_two))[:, order]\n",
    "    aucs, delongcov = fastDeLong(predictions_sorted_transposed, label_1_count)\n",
    "    # print(aucs, delongcov)\n",
    "    return calc_pvalue(aucs, delongcov, logv=logv)\n",
    "\n",
    "\n",
    "def calc_95_CI(ground_truth, predictions, alpha=0.95, with_auc: bool = True):\n",
    "    auc, auc_cov = delong_roc_variance(ground_truth, predictions)\n",
    "    auc_std = np.sqrt(auc_cov)\n",
    "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
    "    ci = scipy.stats.norm.ppf(lower_upper_q, loc=auc, scale=auc_std)\n",
    "    ci[ci > 1] = 1\n",
    "    ci[ci < 0] = 0\n",
    "    if with_auc:\n",
    "        return auc, ci\n",
    "    else:\n",
    "        return ci\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    preds_A = np.array([.5, .5, .5, .5, .5, .5, .5, .5, .5, .8])\n",
    "    preds_B = np.array([.2, .5, .1, .4, .9, .8, .7, .5, .9, .8])\n",
    "    actual = np.array([0, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
    "    print(delong_roc_test(actual, preds_A, preds_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sm\n",
    "from scipy import stats\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.utils import column_or_1d, check_consistent_length, assert_all_finite\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "\n",
    "def calc_array_95ci(data, confidence=0.95):\n",
    "    data = column_or_1d(np.array(data))\n",
    "    std = stats.tstd(data)\n",
    "    sem = stats.sem(data)\n",
    "    return stats.t.interval(confidence, df=len(data) - 1, loc=np.mean(data), scale=sem)\n",
    "\n",
    "\n",
    "def calc_value_95ci(a, b) -> tuple:\n",
    "    \"\"\"\n",
    "    实现： Wilson, E. B. \"Probable Inference, the Law of Succession, and Statistical Inference,\"\n",
    "          Journal of the American Statistical Association, 22, 209-212 (1927).\n",
    "\n",
    "    Args:\n",
    "        a: 分子\n",
    "        b: 分母\n",
    "\n",
    "    Returns: 95% CI [lower, upper]\n",
    "\n",
    "    \"\"\"\n",
    "    sum_value = a + b + 1e-6\n",
    "    ratio = a / sum_value\n",
    "    std = (ratio * (1 - ratio) / sum_value) ** 0.5\n",
    "    return max(0, ratio - 1.96 * std), min(ratio + 1.96 * std, 1)\n",
    "\n",
    "\n",
    "def map_ci(ci):\n",
    "    ci_float = [float(f\"{i_:.6f}\") for i_ in ci]\n",
    "    ci_float[0] = ci_float[0] if not np.isnan(ci_float[0]) else 1\n",
    "    ci_float[1] = ci_float[1] if not np.isnan(ci_float[1]) else 1\n",
    "    # print(ci_float)\n",
    "    return ci_float\n",
    "\n",
    "\n",
    "def check_pos_label_consistency(pos_label, y_true):\n",
    "    \"\"\"Check if `pos_label` need to be specified or not.\n",
    "\n",
    "    In binary classification, we fix `pos_label=1` if the labels are in the set\n",
    "    {-1, 1} or {0, 1}. Otherwise, we raise an error asking to specify the\n",
    "    `pos_label` parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pos_label : int, str or None\n",
    "        The positive label.\n",
    "    y_true : ndarray of shape (n_samples,)\n",
    "        The target vector.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pos_label : int\n",
    "        If `pos_label` can be inferred, it will be returned.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        In the case that `y_true` does not have label in {-1, 1} or {0, 1},\n",
    "        it will raise a `ValueError`.\n",
    "    \"\"\"\n",
    "    # ensure binary classification if pos_label is not specified\n",
    "    # classes.dtype.kind in ('O', 'U', 'S') is required to avoid\n",
    "    # triggering a FutureWarning by calling np.array_equal(a, b)\n",
    "    # when elements in the two arrays are not comparable.\n",
    "    classes = np.unique(y_true)\n",
    "    if (pos_label is None and (\n",
    "            classes.dtype.kind in 'OUS' or\n",
    "            not (np.array_equal(classes, [0, 1]) or\n",
    "                 np.array_equal(classes, [-1, 1]) or\n",
    "                 np.array_equal(classes, [0]) or\n",
    "                 np.array_equal(classes, [-1]) or\n",
    "                 np.array_equal(classes, [1])))):\n",
    "        classes_repr = \", \".join(repr(c) for c in classes)\n",
    "        raise ValueError(\n",
    "            f\"y_true takes value in {{{classes_repr}}} and pos_label is not \"\n",
    "            f\"specified: either make y_true take value in {{0, 1}} or \"\n",
    "            f\"{{-1, 1}} or pass pos_label explicitly.\"\n",
    "        )\n",
    "    elif pos_label is None:\n",
    "        pos_label = 1.0\n",
    "\n",
    "    return pos_label\n",
    "\n",
    "\n",
    "def _binary_clf_curve(y_true, y_score, pos_label=None, sample_weight=None):\n",
    "    \"\"\"Calculate true and false positives per binary classification threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (n_samples,)\n",
    "        True targets of binary classification.\n",
    "\n",
    "    y_score : ndarray of shape (n_samples,)\n",
    "        Estimated probabilities or output of a decision function.\n",
    "\n",
    "    pos_label : int or str, default=None\n",
    "        The label of the positive class.\n",
    "\n",
    "    sample_weight : array-like of shape (n_samples,), default=None\n",
    "        Sample weights.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fps : ndarray of shape (n_thresholds,)\n",
    "        A count of false positives, at index i being the number of negative\n",
    "        samples assigned a score >= thresholds[i]. The total number of\n",
    "        negative samples is equal to fps[-1] (thus true negatives are given by\n",
    "        fps[-1] - fps).\n",
    "\n",
    "    tps : ndarray of shape (n_thresholds,)\n",
    "        An increasing count of true positives, at index i being the number\n",
    "        of positive samples assigned a score >= thresholds[i]. The total\n",
    "        number of positive samples is equal to tps[-1] (thus false negatives\n",
    "        are given by tps[-1] - tps).\n",
    "\n",
    "    thresholds : ndarray of shape (n_thresholds,)\n",
    "        Decreasing score values.\n",
    "    \"\"\"\n",
    "    # Check to make sure y_true is valid\n",
    "    y_type = type_of_target(y_true)\n",
    "    if not (y_type == \"binary\" or\n",
    "            (y_type == \"multiclass\" and pos_label is not None)):\n",
    "        raise ValueError(\"{0} format is not supported\".format(y_type))\n",
    "\n",
    "    check_consistent_length(y_true, y_score, sample_weight)\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_score = column_or_1d(y_score)\n",
    "    assert_all_finite(y_true)\n",
    "    assert_all_finite(y_score)\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        sample_weight = column_or_1d(sample_weight)\n",
    "\n",
    "    pos_label = check_pos_label_consistency(pos_label, y_true)\n",
    "\n",
    "    # make y_true a boolean vector\n",
    "    y_true = (y_true == pos_label)\n",
    "\n",
    "    # sort scores and corresponding truth values\n",
    "    desc_score_indices = np.argsort(y_score, kind=\"mergesort\")[::-1]\n",
    "    y_score = y_score[desc_score_indices]\n",
    "    y_true = y_true[desc_score_indices]\n",
    "    if sample_weight is not None:\n",
    "        weight = sample_weight[desc_score_indices]\n",
    "    else:\n",
    "        weight = 1.\n",
    "\n",
    "    # y_score typically has many tied values. Here we extract\n",
    "    # the indices associated with the distinct values. We also\n",
    "    # concatenate a value for the end of the curve.\n",
    "    distinct_value_indices = np.where(np.diff(y_score))[0]\n",
    "    threshold_idxs = np.r_[distinct_value_indices, y_true.size - 1]\n",
    "\n",
    "    # accumulate the true positives with decreasing threshold\n",
    "    tps = stable_cumsum(y_true * weight)[threshold_idxs]\n",
    "    if sample_weight is not None:\n",
    "        # express fps as a cumsum to ensure fps is increasing even in\n",
    "        # the presence of floating point errors\n",
    "        fps = stable_cumsum((1 - y_true) * weight)[threshold_idxs]\n",
    "    else:\n",
    "        fps = 1 + threshold_idxs - tps\n",
    "    tns = fps[-1] - fps\n",
    "    fns = tps[-1] - tps\n",
    "    return fps, tps, tns, fns, y_score[threshold_idxs]\n",
    "\n",
    "\n",
    "def any_curve(y_true, y_score, *, pos_label=None, sample_weight=None):\n",
    "    fps, tps, tns, fns, thresholds = _binary_clf_curve(\n",
    "        y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n",
    "\n",
    "    if fps[-1] <= 0:\n",
    "        warnings.warn(\"No negative samples in y_true, \"\n",
    "                      \"false positive value should be meaningless\",\n",
    "                      UndefinedMetricWarning)\n",
    "        fpr = np.repeat(np.nan, fps.shape)\n",
    "    else:\n",
    "        fpr = fps / fps[-1]\n",
    "\n",
    "    if tps[-1] <= 0:\n",
    "        warnings.warn(\"No positive samples in y_true, \"\n",
    "                      \"true positive value should be meaningless\",\n",
    "                      UndefinedMetricWarning)\n",
    "        tpr = np.repeat(np.nan, tps.shape)\n",
    "    else:\n",
    "        tpr = tps / tps[-1]\n",
    "\n",
    "    if tns[0] <= 0:\n",
    "        warnings.warn(\"No negative samples in y_true, \"\n",
    "                      \"true negative value should be meaningless\",\n",
    "                      UndefinedMetricWarning)\n",
    "        tnr = np.repeat(np.nan, tns.shape)\n",
    "    else:\n",
    "        tnr = tns / tns[0]\n",
    "\n",
    "    if fns[0] <= 0:\n",
    "        warnings.warn(\"No positive samples in y_true, \"\n",
    "                      \"false negative value should be meaningless\",\n",
    "                      UndefinedMetricWarning)\n",
    "        fnr = np.repeat(np.nan, fns.shape)\n",
    "    else:\n",
    "        fnr = fns / fns[0]\n",
    "\n",
    "    return fpr, tpr, tnr, fnr, thresholds\n",
    "\n",
    "\n",
    "def calc_sens_spec(y_true, y_score, **kwargs):\n",
    "    fpr, tpr, tnr, fnr, thresholds = any_curve(y_true, y_score)\n",
    "    idx = 0\n",
    "    maxv = -1e6\n",
    "    for i, v in enumerate(tpr - fpr):\n",
    "        if v > maxv:\n",
    "            maxv = v\n",
    "            idx = i\n",
    "    #    idx = np.argmax(tpr - fpr)\n",
    "    return tpr[idx], tnr[idx], thresholds[idx]\n",
    "\n",
    "\n",
    "def analysis_pred_binary(y_true: Union[List, np.ndarray, pd.DataFrame], y_score: Union[List, np.ndarray, pd.DataFrame],\n",
    "                         y_pred: Union[List, np.ndarray, pd.DataFrame] = None, alpha=0.95,\n",
    "                         use_youden: bool = True, with_aux_ci: bool = False):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        y_true:\n",
    "        y_score:\n",
    "        y_pred:\n",
    "        alpha: 0.95\n",
    "        use_youden: 是否使用youden指数\n",
    "        with_aux_ci: 是否输出额外的CI\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    aux_ci = {}\n",
    "    if isinstance(y_score, (list, tuple)):\n",
    "        y_score = np.array(y_score)\n",
    "    y_true = column_or_1d(np.array(y_true))\n",
    "    assert sorted(np.unique(y_true)) == [0, 1], f\"结果必须是2分类！\"\n",
    "    assert len(y_true) == len(y_score), '样本数必须相等！'\n",
    "    if len(y_score.shape) == 2:\n",
    "        y_score = column_or_1d(y_score[:, 1])\n",
    "    elif len(y_score.shape) > 2:\n",
    "        raise ValueError(f\"y_score不支持>2列的数据！现在是{y_score.shape}\")\n",
    "    else:\n",
    "        y_score = column_or_1d(y_score)\n",
    "    tpr, tnr, thres = calc_sens_spec(y_true, y_score)\n",
    "    if y_pred is None:\n",
    "        y_pred = np.array(y_score >= (\n",
    "            thres if use_youden else 0.5)).astype(int)\n",
    "    acc = np.sum(y_true == y_pred) / len(y_true)\n",
    "    tp = np.sum(y_true[y_true == 1] == y_pred[y_true == 1])\n",
    "    tn = np.sum(y_true[y_true == 0] == y_pred[y_true == 0])\n",
    "    fp = np.sum(y_pred[y_true == 0] == 1)\n",
    "    fn = np.sum(y_pred[y_true == 1] == 0)\n",
    "    ppv = tp / (tp + fp + 1e-6)\n",
    "    aux_ci['ppv'] = calc_value_95ci(tp, fp)\n",
    "    npv = tn / (tn + fn + 1e-6)\n",
    "    aux_ci['npv'] = calc_value_95ci(tn, fn)\n",
    "    auc, ci = calc_95_CI(y_true, y_score, alpha=alpha, with_auc=True)\n",
    "    if not use_youden:\n",
    "        tpr = tp / (tp + fn + 1e-6)\n",
    "        tnr = tn / (fp + tn + 1e-6)\n",
    "    aux_ci['sens'] = calc_value_95ci(tp, fn)\n",
    "    aux_ci['spec'] = calc_value_95ci(tn, fp)\n",
    "    f1 = 2 * tpr * ppv / (ppv + tpr)\n",
    "    # print(tp, tn, fp, fn)\n",
    "    if with_aux_ci:\n",
    "        return acc, auc, map_ci(ci), tpr, map_ci(aux_ci['sens']), tnr, map_ci(aux_ci['spec']), \\\n",
    "            ppv, map_ci(aux_ci['ppv']), npv, map_ci(\n",
    "                aux_ci['npv']), ppv, tpr, f1, thres\n",
    "    else:\n",
    "        return acc, auc, map_ci(ci), tpr, tnr, ppv, npv, ppv, tpr, f1, thres\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    y_true_ = [0, 0, 1, 1, 1, 1, 0]\n",
    "    y_pred_ = [1, 1, 0, 0, 0, 0, 1]\n",
    "    event_ = [1, 1, 0, 0, 0, 0, 1]\n",
    "    y_pred_1 = [0.51, 0.61, 0.0, 0.01, 0.53, 0.99, 0.88]\n",
    "    y_pred_2 = [1, 0.61, 1, 0.01, 0.53, 0.99, 0.88]\n",
    "    print(analysis_pred_binary(y_true_, y_pred_1, with_aux_ci=True))\n",
    "    print(calc_value_95ci(0, 2))\n",
    "    # print(IDI(y_true_, pred_x=y_pred_2, pred_y=y_pred_1))\n",
    "    # print(NRI(y_true_, y_pred_, event_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "predictions = [[(model.predict(X_train_sel), model.predict(X_test_sel))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "pred_scores = [[(model.predict_proba(X_train_sel), model.predict_proba(X_test_sel))\n",
    "                for model in target] for label, target in zip(labels, targets)]\n",
    "\n",
    "metric = []\n",
    "pred_sel_idx = []\n",
    "for label, prediction, scores in zip(labels, predictions, pred_scores):\n",
    "    pred_sel_idx_label = []\n",
    "    for mname, (train_pred, test_pred), (train_score, test_score) in zip(model_names, prediction, scores):\n",
    "        # 计算训练集指数\n",
    "        acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y_train_sel[label],\n",
    "                                                                                              train_score[:, 1])\n",
    "        ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "        metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv,\n",
    "                      precision, recall, f1, thres, f\"{label}-train\"))\n",
    "\n",
    "        # 计算验证集指标\n",
    "        acc, auc, ci, tpr, tnr, ppv, npv, precision, recall, f1, thres = analysis_pred_binary(y_test_sel[label],\n",
    "                                                                                              test_score[:, 1])\n",
    "        ci = f\"{ci[0]:.4f} - {ci[1]:.4f}\"\n",
    "        metric.append((mname, acc, auc, ci, tpr, tnr, ppv, npv,\n",
    "                      precision, recall, f1, thres, f\"{label}-test\"))\n",
    "        # 计算thres对应的sel idx\n",
    "        pred_sel_idx_label.append(np.logical_or(\n",
    "            test_score[:, 0] >= thres, test_score[:, 1] >= thres))\n",
    "\n",
    "    pred_sel_idx.append(pred_sel_idx_label)\n",
    "metric = pd.DataFrame(metric, index=None, columns=['model_name', 'Accuracy', 'AUC', '95% CI',\n",
    "                                                   'Sensitivity', 'Specificity',\n",
    "                                                   'PPV', 'NPV', 'Precision', 'Recall', 'F1',\n",
    "                                                   'Threshold', 'Task'])\n",
    "metric\n",
    "metric.to_csv('.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
